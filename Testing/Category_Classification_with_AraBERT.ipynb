{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NcMplCCFUPBP"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4mZ8KYblg-g"
      },
      "source": [
        "#installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4tlwQ8si_FI",
        "outputId": "f0509aff-922c-4c53-9d51-deb858d26e76"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Mon Dec 26 18:25:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0    31W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaJf2e5VyNbK"
      },
      "source": [
        "This notebook works fine with transformers 4.12, it is not tested on newer versions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y024z5AnlTLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c9869d-f52e-4202-f446-b67af36eb9cf"
      },
      "source": [
        "!pip install transformers==4.12.2\n",
        "!pip install farasapy==0.0.14\n",
        "!pip install pyarabic==0.6.14\n",
        "!git clone https://github.com/aub-mind/arabert\n",
        "!pip install emoji==1.6.1\n",
        "!pip install sentencepiece==0.1.96"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.12.2\n",
            "  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 31.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 76.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.12.2) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.12.2) (6.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 69.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.12.2) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.12.2) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.12.2) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.12.2) (3.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.12.2) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 75.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.0.17->transformers==4.12.2) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.12.2) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.12.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.12.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.12.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.12.2) (2022.12.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.12.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.12.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.12.2) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=2ef2bf4ec496de334e2c7c8e2898f428a44cb87f78e231e5bc578486b10dd40b\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.12.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting farasapy==0.0.14\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farasapy==0.0.14) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farasapy==0.0.14) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy==0.0.14) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy==0.0.14) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy==0.0.14) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy==0.0.14) (2022.12.7)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarabic==0.6.14\n",
            "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 32.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic==0.6.14) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.14\n",
            "Cloning into 'arabert'...\n",
            "remote: Enumerating objects: 600, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (600/600), 9.14 MiB | 35.06 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji==1.6.1\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 29.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169313 sha256=d10759b90973156c87640662e902c58d1ccc9853cc472252f32052889895df68\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/29/50/1e7189f03d2cf139e469863d54a1d3eabeb10c92c84e51f8a1\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 30.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f3KKtL5yMub"
      },
      "source": [
        "Let's download some Arabic text classification datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpdi0DENyLmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d66b54-5278-41df-bae2-4859a201bfa4"
      },
      "source": [
        "!git clone https://github.com/elnagara/HARD-Arabic-Dataset\n",
        "!git clone https://github.com/mahmoudnabil/ASTD\n",
        "!git clone https://github.com/nora-twairesh/AraSenti\n",
        "!git clone https://github.com/mohamedadaly/LABR\n",
        "!wget http://homepages.inf.ed.ac.uk/wmagdy/Resources/ArSAS.zip\n",
        "!unzip ArSAS.zip\n",
        "!unrar x '/content/HARD-Arabic-Dataset/data/unbalanced-reviews.rar'\n",
        "!unzip '/content/HARD-Arabic-Dataset/data/balanced-reviews.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HARD-Arabic-Dataset'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Total 100 (delta 0), reused 0 (delta 0), pack-reused 100\u001b[K\n",
            "Receiving objects: 100% (100/100), 116.36 MiB | 29.69 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "Cloning into 'ASTD'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Total 29 (delta 0), reused 0 (delta 0), pack-reused 29\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n",
            "Cloning into 'AraSenti'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Total 20 (delta 0), reused 0 (delta 0), pack-reused 20\u001b[K\n",
            "Unpacking objects: 100% (20/20), done.\n",
            "Cloning into 'LABR'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n",
            "--2022-12-26 18:26:16--  http://homepages.inf.ed.ac.uk/wmagdy/Resources/ArSAS.zip\n",
            "Resolving homepages.inf.ed.ac.uk (homepages.inf.ed.ac.uk)... 129.215.32.113\n",
            "Connecting to homepages.inf.ed.ac.uk (homepages.inf.ed.ac.uk)|129.215.32.113|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://homepages.inf.ed.ac.uk/wmagdy/Resources/ArSAS.zip [following]\n",
            "--2022-12-26 18:26:17--  https://homepages.inf.ed.ac.uk/wmagdy/Resources/ArSAS.zip\n",
            "Connecting to homepages.inf.ed.ac.uk (homepages.inf.ed.ac.uk)|129.215.32.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1905723 (1.8M) [application/zip]\n",
            "Saving to: ‘ArSAS.zip’\n",
            "\n",
            "ArSAS.zip           100%[===================>]   1.82M  2.92MB/s    in 0.6s    \n",
            "\n",
            "2022-12-26 18:26:18 (2.92 MB/s) - ‘ArSAS.zip’ saved [1905723/1905723]\n",
            "\n",
            "Archive:  ArSAS.zip\n",
            "  inflating: ArSAS..txt              \n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/HARD-Arabic-Dataset/data/unbalanced-reviews.rar\n",
            "\n",
            "Extracting  unbalanced-reviews.txt                                       \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "Archive:  /content/HARD-Arabic-Dataset/data/balanced-reviews.zip\n",
            "  inflating: balanced-reviews.txt    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcwdslw7v0Q8"
      },
      "source": [
        "#Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhcYKB663eoz"
      },
      "source": [
        "Start the training procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUn2RB6Bvrxj"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             confusion_matrix, f1_score, precision_score,\n",
        "                             recall_score)\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, BertTokenizer, Trainer,\n",
        "                          TrainingArguments)\n",
        "from transformers.data.processors.utils import InputFeatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tv-ZwCt3iZE"
      },
      "source": [
        "List all the datasets we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4SGYoB2EDJD"
      },
      "source": [
        "from sklearn import model_selection\n",
        "##############For Training Data#####################\n",
        "# Read the data from the csv file named 'preprocessedData.csv' arabic data\n",
        "train1 = pd.read_csv('./cleaned_train.csv', encoding='utf-8')\n",
        "train2 = pd.read_csv('./cleaned_dev.csv', encoding='utf-8')\n",
        "\n",
        "train = pd.concat([train1, train2], ignore_index=True)\n",
        "\n",
        "\n",
        "# Split the data into train and test\n",
        "train, test = model_selection.train_test_split(train, test_size=0.01)\n",
        "# Unpack the data into text and stance\n",
        "Train_X = train['text']\n",
        "stance_Train_Y = train['stance']\n",
        "cat_Train_Y = train['category']\n",
        "\n",
        "# Unpack the data into text, and stance\n",
        "Test_X = test['text']\n",
        "stance_Test_Y = test['stance']\n",
        "cat_Test_Y = test['category']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzeVFoz1wDYf"
      },
      "source": [
        "# select a model from the huggingface modelhub https://huggingface.co/models?language=ar\n",
        "model_name = 'aubmindlab/bert-base-arabertv02-twitter' # we are going to use the twitter AraBERT since it has emojis and dialects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icuhwx3S4NLM"
      },
      "source": [
        "Create and apply preprocessing using the AraBERT processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt_lGy85zuca"
      },
      "source": [
        "arabic_prep = ArabertPreprocessor(model_name)\n",
        "Train_X = Train_X.apply(lambda x: arabic_prep.preprocess(x))\n",
        "Test_X = Test_X.apply(lambda x: arabic_prep.preprocess(x))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH2yldN-4vcX"
      },
      "source": [
        "Now we need to check the tokenized sentence length to decide on the maximum sentence length value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOVdVmfEguAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8dc74c-bcec-4168-f00a-369a1d2bdb79"
      },
      "source": [
        "tok = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "pP5ziUabgpeb",
        "outputId": "3e9f6fd6-d777-46a7-f3dc-0099425f338b"
      },
      "source": [
        "print(\"Training Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in Train_X.to_list()],bins=range(0,128,2))\n",
        "plt.show()\n",
        "\n",
        "print(\"Testing Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in Test_X.to_list()],bins=range(0,128,2))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSDt3uyd5K2C"
      },
      "source": [
        "Let's select 100 as our maximum sentence length, and check how many sequences will be truncated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLhNqO2w5DIn",
        "outputId": "d9868f5a-1faf-45c1-eec8-dea438ea578a"
      },
      "source": [
        "max_len = 120\n",
        "print(\"Truncated training sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in Test_X.to_list()]))\n",
        "\n",
        "print(\"Truncated testing sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in Test_X.to_list()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncated training sequences:  0\n",
            "Truncated testing sequences:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwDilG055gtf"
      },
      "source": [
        "8 out of ~4000 for testing isn't bad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqENWrht6A5n"
      },
      "source": [
        "Now let's create a classification dataset to load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YS7XI2bZTyz"
      },
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(ClassificationDataset).__init__()\n",
        "      \"\"\"\n",
        "      Args:\n",
        "      text (List[str]): List of the training text\n",
        "      target (List[str]): List of the training labels\n",
        "      tokenizer_name (str): The tokenizer name (same as model_name).\n",
        "      max_len (int): Maximum sentence length\n",
        "      label_map (Dict[str,int]): A dictionary that maps the class labels to integer\n",
        "      \"\"\"\n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "      \n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "        \n",
        "      inputs = self.tokenizer(\n",
        "          text,\n",
        "          max_length=self.max_len,\n",
        "          padding='max_length',\n",
        "          truncation=True\n",
        "      )      \n",
        "      return InputFeatures(**inputs,label=self.label_map[self.target[item]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mciZOFz-amkV",
        "outputId": "ce63af7b-8809-428c-91b2-1c71be4f8f80"
      },
      "source": [
        "\n",
        "label_map = { v:index for index, v in enumerate(['info_news', 'personal', 'celebrity', 'plan', 'unrelated', 'others', 'requests', 'rumors', 'advice', 'restrictions']) }\n",
        "print(label_map)\n",
        "\n",
        "train_dataset = ClassificationDataset(\n",
        "    Train_X.to_list(),\n",
        "    cat_Train_Y.to_list(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )\n",
        "test_dataset = ClassificationDataset(\n",
        "    Test_X.to_list(),\n",
        "    cat_Test_Y.to_list(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'info_news': 0, 'personal': 1, 'celebrity': 2, 'plan': 3, 'unrelated': 4, 'others': 5, 'requests': 6, 'rumors': 7, 'advice': 8, 'restrictions': 9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoOyOzRu8Jwo"
      },
      "source": [
        "Check the dataset output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhi41co270I9",
        "outputId": "d6dddd66-c45c-4836-eb7c-8c0ac1838c59"
      },
      "source": [
        "print(next(iter(train_dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InputFeatures(input_ids=[2, 16611, 1864, 1089, 4155, 463, 1451, 16136, 40204, 1163, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFHzbq6p8P2C"
      },
      "source": [
        "Create a function that return a pretrained model ready to do classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt7l0IxjbmNu"
      },
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WCYBfiB8hIb"
      },
      "source": [
        "Define whatever metric you want here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYU6G4vWc5nz"
      },
      "source": [
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  #print(classification_report(p.label_ids,preds))\n",
        "  #print(confusion_matrix(p.label_ids,preds))\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  #macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  #macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {       \n",
        "      'macro_f1' : macro_f1,\n",
        "      'accuracy': acc\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEznOOD4COn7"
      },
      "source": [
        "def set_seed(seed=42):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic=True\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTmvFEs41WkV"
      },
      "source": [
        "#Regular Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hym-1aiJ8zS8"
      },
      "source": [
        "Define our training parameters.\n",
        "Check the TrainingArguments documentation for more options https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BplVarm6h6qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3d39ed-041b-4903-f7d7-d0b5b14cfbd8"
      },
      "source": [
        "training_args = TrainingArguments( \n",
        "    output_dir= \"./train\",    \n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = False, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 2,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 25\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVODSK3D89OZ"
      },
      "source": [
        "Create the trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro5BW5ak4uc1",
        "outputId": "cce16e28-5434-48b4-84fa-e8a8b14a57f4"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1109ac490c1eb90f74960e17c00032f27ea3c4be159567d7ed5d2b5908f9855c.01294502d101541d98086466d32c6b4f04698a90a573cd06480d05bd0c20b2aa\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-arabertv02\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1f7c10cecf08743620c7e224e2f3c6b072e45aee1e88fa324837fd199cf24f21.e7b697f3572c7ddd6984e105b6c6cacc07a625d1195f9be544d26d3ad7d0e442\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "mxqoZsFWSFso",
        "outputId": "f1bf8542-1c56-4cac-de6c-dd05eac2f44e"
      },
      "source": [
        "#start the training\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 7908\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 494\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 05:33, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.950999</td>\n",
              "      <td>0.319343</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.908927</td>\n",
              "      <td>0.314630</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 80\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train/checkpoint-247\n",
            "Configuration saved in ./train/checkpoint-247/config.json\n",
            "Model weights saved in ./train/checkpoint-247/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 80\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train/checkpoint-494\n",
            "Configuration saved in ./train/checkpoint-494/config.json\n",
            "Model weights saved in ./train/checkpoint-494/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train/checkpoint-247 (score: 0.3193433179723502).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=494, training_loss=0.9960382747264044, metrics={'train_runtime': 334.2517, 'train_samples_per_second': 47.318, 'train_steps_per_second': 1.478, 'total_flos': 975143165028480.0, 'train_loss': 0.9960382747264044, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZJE_H0j-ldm"
      },
      "source": [
        "Save the model, the tokenizer and the config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pru84em-lMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2c6e4f-54ed-43ac-b8d0-f38e5811a4e9"
      },
      "source": [
        "inv_label_map = inv_label_map = { v:k for k, v in label_map.items()}\n",
        "print(inv_label_map)\n",
        "trainer.model.config.label2id = label_map\n",
        "trainer.model.config.id2label = inv_label_map\n",
        "trainer.save_model(\"output_dir\")\n",
        "train_dataset.tokenizer.save_pretrained(\"output_dir\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to output_dir\n",
            "Configuration saved in output_dir/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'info_news', 1: 'personal', 2: 'celebrity', 3: 'plan', 4: 'unrelated', 5: 'others', 6: 'requests', 7: 'rumors', 8: 'advice', 9: 'restrictions'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in output_dir/pytorch_model.bin\n",
            "tokenizer config file saved in output_dir/tokenizer_config.json\n",
            "Special tokens file saved in output_dir/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('output_dir/tokenizer_config.json',\n",
              " 'output_dir/special_tokens_map.json',\n",
              " 'output_dir/vocab.txt',\n",
              " 'output_dir/added_tokens.json',\n",
              " 'output_dir/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gqU_1BC0558",
        "outputId": "33cb99f9-0be2-488c-f15e-8359a3b9a6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckb8jYZu_pCu"
      },
      "source": [
        "#copy the model to drive\n",
        "!cp -r output_dir /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaDLMebgF8EE"
      },
      "source": [
        "## predict using the saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFqMbH5uF-TR"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx4k9zqkF7Wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aee1355-08c3-49fe-c4c9-0ce224213d12"
      },
      "source": [
        "# initialize pipline\n",
        "pipe = pipeline(\"sentiment-analysis\", model=\"output_dir\", device=0, return_all_scores=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file output_dir/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"info_news\",\n",
            "    \"1\": \"personal\",\n",
            "    \"2\": \"celebrity\",\n",
            "    \"3\": \"plan\",\n",
            "    \"4\": \"unrelated\",\n",
            "    \"5\": \"others\",\n",
            "    \"6\": \"requests\",\n",
            "    \"7\": \"rumors\",\n",
            "    \"8\": \"advice\",\n",
            "    \"9\": \"restrictions\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"advice\": 8,\n",
            "    \"celebrity\": 2,\n",
            "    \"info_news\": 0,\n",
            "    \"others\": 5,\n",
            "    \"personal\": 1,\n",
            "    \"plan\": 3,\n",
            "    \"requests\": 6,\n",
            "    \"restrictions\": 9,\n",
            "    \"rumors\": 7,\n",
            "    \"unrelated\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading configuration file output_dir/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"info_news\",\n",
            "    \"1\": \"personal\",\n",
            "    \"2\": \"celebrity\",\n",
            "    \"3\": \"plan\",\n",
            "    \"4\": \"unrelated\",\n",
            "    \"5\": \"others\",\n",
            "    \"6\": \"requests\",\n",
            "    \"7\": \"rumors\",\n",
            "    \"8\": \"advice\",\n",
            "    \"9\": \"restrictions\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"advice\": 8,\n",
            "    \"celebrity\": 2,\n",
            "    \"info_news\": 0,\n",
            "    \"others\": 5,\n",
            "    \"personal\": 1,\n",
            "    \"plan\": 3,\n",
            "    \"requests\": 6,\n",
            "    \"restrictions\": 9,\n",
            "    \"rumors\": 7,\n",
            "    \"unrelated\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file output_dir/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at output_dir.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "Didn't find file output_dir/added_tokens.json. We won't load it.\n",
            "loading file output_dir/vocab.txt\n",
            "loading file output_dir/tokenizer.json\n",
            "loading file None\n",
            "loading file output_dir/special_tokens_map.json\n",
            "loading file output_dir/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ecQR0_tGDQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81179e4-29cb-4f4c-8c59-91af74d1759c"
      },
      "source": [
        "import csv\n",
        "\n",
        "dataframe = pd.DataFrame\n",
        "\n",
        "Test_Data = pd.read_csv('cleaned_test_farasa.csv', encoding='utf-8')\n",
        "fields = ['id','category']\n",
        "\n",
        "data_frame = pd.DataFrame(columns=fields)\n",
        "\n",
        "for i in range(len(Test_Data)):\n",
        "\n",
        "  id = Test_Data['id'][i]\n",
        "  text = Test_Data['text'][i]\n",
        "\n",
        "  prediction_list_dict = pipe(text)[0]\n",
        "  # [{'label': 'info_news', 'score': 0.32171744108200073}]\n",
        "\n",
        "  final_label = \"\"\n",
        "  final_score = -1\n",
        "\n",
        "  for label_score in prediction_list_dict:\n",
        "    label = label_score['label']\n",
        "    score = label_score['score']\n",
        "    if score > final_score:\n",
        "      final_score = score \n",
        "      final_label = label\n",
        "  data_frame = data_frame.append({'id': id, 'category': final_label}, ignore_index=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:908: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FlUSQGGT2uxq",
        "outputId": "19b96573-c3a9-4c1e-8253-839c8e39415c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id   category\n",
              "0        0  celebrity\n",
              "1        1  unrelated\n",
              "2        2   personal\n",
              "3        3  info_news\n",
              "4        4  info_news\n",
              "...    ...        ...\n",
              "1995  1995  info_news\n",
              "1996  1996   personal\n",
              "1997  1997  info_news\n",
              "1998  1998  info_news\n",
              "1999  1999  unrelated\n",
              "\n",
              "[2000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0a6d1c0-f5c5-4506-ab77-a7bf7c1077b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>celebrity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>personal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>info_news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>info_news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1995</td>\n",
              "      <td>info_news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1996</td>\n",
              "      <td>personal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1997</td>\n",
              "      <td>info_news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1998</td>\n",
              "      <td>info_news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1999</td>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0a6d1c0-f5c5-4506-ab77-a7bf7c1077b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0a6d1c0-f5c5-4506-ab77-a7bf7c1077b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0a6d1c0-f5c5-4506-ab77-a7bf7c1077b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.to_csv(\"results_category.csv\",index=False)"
      ],
      "metadata": {
        "id": "YYiT5J8aFZwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnZnSsg7Fjud",
        "outputId": "0a5d1bf1-c744-40da-b1a2-2783bce7f217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34marabert\u001b[0m/              cleaned_test_farasa.csv  results_category.csv\n",
            "\u001b[01;34mAraSenti\u001b[0m/             cleaned_train.csv        \u001b[01;34msample_data\u001b[0m/\n",
            "ArSAS..txt            dev.csv                  test.csv\n",
            "ArSAS.zip             \u001b[01;34mdrive\u001b[0m/                   \u001b[01;34mtrain\u001b[0m/\n",
            "\u001b[01;34mASTD\u001b[0m/                 \u001b[01;34mHARD-Arabic-Dataset\u001b[0m/     train.csv\n",
            "balanced-reviews.txt  \u001b[01;34mLABR\u001b[0m/                    unbalanced-reviews.txt\n",
            "cleaned_dev.csv       \u001b[01;34moutput_dir\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcS3oIRmFoUZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}