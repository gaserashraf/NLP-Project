{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from preprocessing import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Model Classification with Skip-Gram Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############For Training Data#####################\n",
    "# Read the data from the csv file named 'preprocessedData.csv' arabic data\n",
    "train = pd.read_csv('../Dataset/cleaned_train.csv', encoding='utf-8')\n",
    "# Unpack the data into text and stance\n",
    "Train_X = train['text']\n",
    "Train_X = [x.split(\" \") for x in Train_X]\n",
    "stance_Train_Y = train['stance']\n",
    "cat_Train_Y = train['category']\n",
    "\n",
    "##############For Testing Data#####################\n",
    "test = pd.read_csv('../Dataset/cleaned_dev.csv', encoding='utf-8')\n",
    "# Perform the data preprocessing\n",
    "test = clean_data(test)\n",
    "# Unpack the data into text, and stance\n",
    "Test_X = test['text']\n",
    "Test_X = [x.split(\" \") for x in Test_X]\n",
    "stance_Test_Y = test['stance']\n",
    "cat_Test_Y = test['category']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the pre-trained skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we want to apply Skip-Gram model to the data\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load the model\n",
    "sg_model = KeyedVectors.load_word2vec_format('../model/Word2VecSkipGram300D.bin', binary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the embeddings as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training words not in the model:  36311\n",
      "Number of testing words not in the model:  5008\n"
     ]
    }
   ],
   "source": [
    "# Loop over the training data and replace each word with its embedding\n",
    "# Store the embedding in a different array\n",
    "\n",
    "\n",
    "max_len = 0\n",
    "for i in range(len(Train_X)):\n",
    "    if len(Train_X[i]) > max_len:\n",
    "        max_len = len(Train_X[i])\n",
    "\n",
    "counter = 0\n",
    "Train_X_sg = np.zeros((len(Train_X), max_len, 300))\n",
    "for i in range(len(Train_X)):\n",
    "    for j in range(len(Train_X[i])):\n",
    "        if Train_X[i][j] in sg_model:\n",
    "            Train_X_sg[i][j] = sg_model[Train_X[i][j]]\n",
    "        else:\n",
    "            counter += 1\n",
    "print(\"Number of training words not in the model: \", counter)\n",
    "counter = 0\n",
    "Test_X_sg = np.zeros((len(Test_X), max_len, 300))\n",
    "for i in range(len(Test_X)):\n",
    "    for j in range(len(Test_X[i])):\n",
    "        if Test_X[i][j] in sg_model:\n",
    "            Test_X_sg[i][j] = sg_model[Test_X[i][j]]\n",
    "        else:\n",
    "            counter += 1\n",
    "print(\"Number of testing words not in the model: \", counter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Stance Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SMOTE to the training data to balance the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 5538, 0: 1012, -1: 438})\n",
      "Counter({1: 5538, 0: 5538, -1: 5538})\n"
     ]
    }
   ],
   "source": [
    "Train_X_sg_shaped = np.reshape(Train_X_sg, (len(Train_X_sg), -1))\n",
    "# Here we want to apply SMOTE to the data to balance the data against 3 classes\n",
    "# Count the number of each class\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print(Counter(stance_Train_Y))\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "SMOTE_Train_X_sg, SMOTE_stance_Train_Y = oversample.fit_resample(Train_X_sg_shaped, stance_Train_Y)\n",
    "print(Counter(SMOTE_stance_Train_Y))\n",
    "# Reshape the data to be 3D\n",
    "SMOTE_Train_X_sg = np.reshape(SMOTE_Train_X_sg, (len(SMOTE_Train_X_sg), max_len, 300))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "219/219 [==============================] - 8s 13ms/step - loss: 0.6659 - accuracy: 0.7902\n",
      "Epoch 2/12\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6422 - accuracy: 0.7915\n",
      "Epoch 3/12\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6297 - accuracy: 0.7918\n",
      "Epoch 4/12\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.6160 - accuracy: 0.7912\n",
      "Epoch 5/12\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.6439 - accuracy: 0.7925\n",
      "Epoch 6/12\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.6444 - accuracy: 0.7925\n",
      "Epoch 7/12\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6424 - accuracy: 0.7925\n",
      "Epoch 8/12\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6432 - accuracy: 0.7925\n",
      "Epoch 9/12\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6408 - accuracy: 0.7925\n",
      "Epoch 10/12\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6429 - accuracy: 0.7925\n",
      "Epoch 11/12\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.6412 - accuracy: 0.7925\n",
      "Epoch 12/12\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6412 - accuracy: 0.7925\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.80      0.89      1000\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.33      0.27      0.30      1000\n",
      "weighted avg       1.00      0.80      0.89      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(128, input_shape=(max_len, 300), return_sequences=True))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(64))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "stance_Train_Y = np.array(stance_Train_Y) + 1\n",
    "# Fit the lstm_model\n",
    "history = lstm_model.fit(Train_X_sg, stance_Train_Y, epochs=12, batch_size=32, verbose=1)\n",
    "predections_lstm = lstm_model.predict(Test_X_sg)\n",
    "print(classification_report(np.argmax(predections_lstm, axis=1), stance_Test_Y+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "520/520 [==============================] - 9s 13ms/step - loss: 1.0999 - accuracy: 0.3338\n",
      "Epoch 2/2\n",
      "520/520 [==============================] - 6s 12ms/step - loss: 1.0991 - accuracy: 0.3311\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.13      0.22      1000\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.13      1000\n",
      "   macro avg       0.33      0.04      0.07      1000\n",
      "weighted avg       1.00      0.13      0.22      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "SMOTE_lstm_model = Sequential()\n",
    "SMOTE_lstm_model.add(LSTM(128, input_shape=(max_len, 300), return_sequences=True))\n",
    "SMOTE_lstm_model.add(Dropout(0.2))\n",
    "SMOTE_lstm_model.add(LSTM(64))\n",
    "SMOTE_lstm_model.add(Dropout(0.2))\n",
    "SMOTE_lstm_model.add(Dense(3, activation='softmax'))\n",
    "SMOTE_lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "SMOTE_stance_Train_Y = np.array(SMOTE_stance_Train_Y) + 1\n",
    "# Fit the SMOTE_lstm_model\n",
    "history = SMOTE_lstm_model.fit(SMOTE_Train_X_sg, SMOTE_stance_Train_Y, epochs=2, batch_size=32, verbose=1)\n",
    "predections_SMOTE_lstm = SMOTE_lstm_model.predict(Test_X_sg)\n",
    "print(classification_report(np.argmax(predections_SMOTE_lstm, axis=1), stance_Test_Y+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Category Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the categories to numbers\n",
    "cat_Train_Y = cat_Train_Y.map({'info_news': 0, 'personal': 1, 'celebrity': 2, 'plan': 3, 'unrelated': 4, 'others': 5, 'requests': 6, 'rumors': 7, 'advice': 8, 'restrictions': 9})\n",
    "cat_Test_Y = cat_Test_Y.map({'info_news': 0, 'personal': 1, 'celebrity': 2, 'plan': 3, 'unrelated': 4, 'others': 5, 'requests': 6, 'rumors': 7, 'advice': 8, 'restrictions': 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "219/219 [==============================] - 6s 15ms/step - loss: nan - accuracy: 0.5169\n",
      "Epoch 2/2\n",
      "219/219 [==============================] - 3s 13ms/step - loss: nan - accuracy: 0.5175\n",
      "32/32 [==============================] - 2s 14ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71      1000\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.10      0.05      0.07      1000\n",
      "weighted avg       1.00      0.55      0.71      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\osama\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "cat_lstm_model = Sequential()\n",
    "cat_lstm_model.add(LSTM(128, input_shape=(max_len, 300), return_sequences=True))\n",
    "cat_lstm_model.add(Dropout(0.2))\n",
    "cat_lstm_model.add(LSTM(64))\n",
    "cat_lstm_model.add(Dropout(0.2))\n",
    "cat_lstm_model.add(Dense(3, activation='softmax'))\n",
    "cat_lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the cat_lstm_model\n",
    "history = cat_lstm_model.fit(Train_X_sg, cat_Train_Y, epochs=2, batch_size=32, verbose=1)\n",
    "predections_lstm = cat_lstm_model.predict(Test_X_sg)\n",
    "print(classification_report(np.argmax(predections_lstm, axis=1), cat_Test_Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79fdc8352940022464368746d67d12dbc9a3740708d0e5e01c2eafb24b507835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
